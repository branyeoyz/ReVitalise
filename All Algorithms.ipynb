{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ew5bcoEzik1E"
      },
      "source": [
        "##Firebase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UnOYyt1mV5y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "929f8e94-53f8-40d6-8bfb-73b91cf1ff4f"
      },
      "source": [
        "from firebase import firebase\n",
        "import csv\n",
        "import os.path as pth\n",
        "#realtime firebase to HS\n",
        "\n",
        "firebase = firebase.FirebaseApplication(\"https://rvcapstone-default-rtdb.asia-southeast1.firebasedatabase.app\", None)\n",
        "\n",
        "import firebase_admin\n",
        "from firebase_admin import credentials\n",
        "from firebase_admin import firestore\n",
        "\n",
        "timestamp = firebase.get('/Data/Timing','')\n",
        "accx = firebase.get('/Data/Acceleration_X','')\n",
        "accy = firebase.get('/Data/Acceleration_Y','')\n",
        "accz = firebase.get('/Data/Acceleration_Z','')\n",
        "rotx = firebase.get('/Data/Rotation_Roll','')\n",
        "roty = firebase.get('/Data/Rotation_Pitch','')\n",
        "rotz = firebase.get('/Data/Rotation_Yaw','')\n",
        "\n",
        "timestamp_list = []\n",
        "accx_list = []\n",
        "accy_list = []\n",
        "accz_list = []\n",
        "rotx_list = []\n",
        "roty_list = []\n",
        "rotz_list = []\n",
        "\n",
        "for value in timestamp.values():\n",
        "    timestamp_list.append(value)\n",
        "for value in accx.values():\n",
        "    accx_list.append(value)\n",
        "for value in accy.values():\n",
        "    accy_list.append(value)\n",
        "for value in accz.values():\n",
        "    accz_list.append(value)\n",
        "for value in rotx.values():\n",
        "    rotx_list.append(value)\n",
        "for value in roty.values():\n",
        "    roty_list.append(value)\n",
        "for value in rotz.values():\n",
        "    rotz_list.append(value)\n",
        "\n",
        "\n",
        "filename = \"session\"\n",
        "filenum = 1\n",
        "while pth.exists(pth.abspath(filename+str(filenum)+\".csv\")):\n",
        "    filenum+=1\n",
        "with open(filename+str(filenum)+'.csv', 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(timestamp_list) #row 1 - row 7 accordingly\n",
        "    writer.writerow(accx_list)\n",
        "    writer.writerow(accy_list)\n",
        "    writer.writerow(accz_list)\n",
        "    writer.writerow(rotx_list)\n",
        "    writer.writerow(accy_list)\n",
        "    writer.writerow(accz_list)\n",
        "    \n",
        "sessionname = filename + str(filenum)\n",
        "print(sessionname)\n",
        "#HS to firestore\n",
        "#remember to give the mainserviceaccountfile to HS too with the code\n",
        "\n",
        "if not firebase_admin._apps:\n",
        "    cred = credentials.Certificate('/content/drive/MyDrive/Colab Notebooks/mainserviceaccount.json') \n",
        "    firebase_admin.initialize_app(cred)\n",
        "\n",
        "db = firestore.client()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "session2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkn50VV_Tc5M",
        "outputId": "51abf47b-8f99-4917-f853-2fa57c48b7b5"
      },
      "source": [
        "#run these with appropriate functions after running \"Final Function\"\n",
        "session = {\n",
        "'approach jump count':450,\n",
        "'block jump count':150,\n",
        "'average approach jump height': 33.5, \n",
        "'average block jump height': 30.0,\n",
        "'max approach jump height': 42.0, \n",
        "'max approach block jump height': 30.5,\n",
        "'total average jump height': 32.0,\n",
        "'peak jump height': 37.0,\n",
        "'total jumps': 600\n",
        "}\n",
        "\n",
        "db.collection('users').document('Bt1OuEGrCKm413CALIqG').collection('trainings').document('week4').collection('sessions').document(str(sessionname)).set(session)\n",
        "\n",
        "#'Below Average',\n",
        "#'A Lot More Work Needs To Be Done On Jumping Mechanics',\n",
        "#'Average',\n",
        "#'Focus On Improving Jumping Mechanics',\n",
        "#'Above Average',\n",
        "#'So Close to Personal Best',\n",
        "#'Excellent',\n",
        "#'It Is A New Personal Best',\n",
        "\n",
        "#'Under Training',\n",
        "#'Increase Jump Count For Training Session',\n",
        "#'Positive Adaptation',\n",
        "#'Jump Count Is Just Right With Low Chance Of Injury',\n",
        "#'Over-Reaching',\n",
        "#'Training Plan Needs To Be Altered As Athlete Has Moderate Chance of Injury',\n",
        "#'Over-Training',\n",
        "#'Training Plan Must Be Restructured As Athlete Has High Chance of Injury',\n",
        "\n",
        "#'Low Readiness',\n",
        "#'Weekly Jump Count Is Far From Competition Readiness'\n",
        "#'Moderate Readiness',\n",
        "#'Increase Weekly Jump Count'\n",
        "#'Competition Ready',\n",
        "#'Athlete Is Ready For Competition'\n",
        "#'Excellent Readiness',\n",
        "#'Athlete Is In Excellent Condition'\n",
        "\n",
        "#mainuser = {\n",
        "#'competition jump': 1800,\n",
        "#'weeks to competition readiness': 3,\n",
        "#'average jump height': 40,\n",
        "#'peak jump height':48,\n",
        "#'performance enhancement rating': 'Above Average',\n",
        "#'injury management rating': 'Positive Adaptation',\n",
        "#'competition readiness rating': 'Excellent Readiness',\n",
        "#}\n",
        "\n",
        "#feedback = {\n",
        "#'id': 'week8',\n",
        "#'total approach jumps':1677,\n",
        "#'total block jumps':523,\n",
        "#'total jumps': 2200,\n",
        "#'peak jump height':46,\n",
        "#'average jump height':0,\n",
        "#'weeks to competition readiness': 0,\n",
        "#'performance enhancement rating':'Above Average',\n",
        "#'performance enhancement feedback': 'So Close to Personal Best',\n",
        "#'injury management rating': 'Positive Adaptation',\n",
        "#'injury management feedback': 'Jump Count Is Just Right With Low Chance Of Injury',\n",
        "#'competition readiness rating': 'Excellent Readiness',\n",
        "#'competition readiness feedback': 'Athlete Is In Excellent Condition'\n",
        "#}\n",
        "\n",
        "#db.collection('users').document('9qK74YxlBco6S3vEf2DG').add()\n",
        "#db.collection('users').document('9qK74YxlBco6S3vEf2DG').collection('trainings').document('week1').set()\n",
        "#db.collection('users').document('9qK74YxlBco6S3vEf2DG').collection('trainings').document('week8').collection('sessions').document('session5').set(session1)\n",
        "\n",
        "#db.collection('users').document('test').collection('trainings').document(str(sessionname)).set(session)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "update_time {\n",
              "  seconds: 1626070791\n",
              "  nanos: 591495000\n",
              "}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GhS3anFEXLC"
      },
      "source": [
        "##All Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBoDNc--EjgI"
      },
      "source": [
        "def data_processing_NEW(link):\n",
        "  #time is already in ms\n",
        "  df = pd.read_csv(link, header=None)\n",
        "  df_t = df.T\n",
        "\n",
        "  ls=[]\n",
        "  #get time stamps\n",
        "  timezero = df_t[0][0]\n",
        "  for i in range(len(df_t)):\n",
        "    ls.append(df_t[0][i]-timezero)\n",
        "  df_t['Time(s)'] = ls\n",
        "\n",
        "\n",
        "  df_t.loc[:, 'Time(s)'] /= 1000\n",
        "  #remove irrelavant columns\n",
        "  df_t.pop(0)\n",
        "\n",
        "  # shift column 'Time(s)' to first position\n",
        "  first_column = df_t.pop('Time(s)')\n",
        "  df_t.insert(0, 'Time(s)', first_column)\n",
        "\n",
        "  #rename columns\n",
        "  df_t.columns = ['Time(s)', 'ax(g)', 'ay(g)', 'az(g)', 'rotX', 'rotY', 'rotZ']\n",
        "\n",
        "  #create new dataframe without repeated timings\n",
        "  #take average of repeated readings\n",
        "\n",
        "  #new_df = pd.DataFrame(data, columns = ['Time(s)', 'ax(g)', 'ay(g)', 'az(g)'])\n",
        "  new_df = pd.DataFrame()\n",
        "  to_append=[]\n",
        "  total = len(df_t)-1\n",
        "  i=0\n",
        "\n",
        "  #remove rotational data\n",
        "  df_t.pop('rotX')\n",
        "  df_t.pop('rotY')\n",
        "  df_t.pop('rotZ')\n",
        "\n",
        "  while i<total:\n",
        "  #for i in range(len(df)-1):\n",
        "    if df_t.iloc[i]['Time(s)']<df_t.iloc[i+1]['Time(s)'] and df_t.iloc[i]['Time(s)']>=0:\n",
        "      new_df = new_df.append(df_t.iloc[i], ignore_index=True)\n",
        "      i +=1\n",
        "    else:\n",
        "      #recalculate\n",
        "      #append into new dataframe\n",
        "      new_x = (df_t.iloc[i]['ax(g)'] + df_t.iloc[i+1]['ax(g)'])/2\n",
        "      new_y = (df_t.iloc[i]['ay(g)'] + df_t.iloc[i+1]['ay(g)'])/2\n",
        "      new_z = (df_t.iloc[i]['az(g)'] + df_t.iloc[i+1]['az(g)'])/2\n",
        "      time = df_t.iloc[i]['Time(s)']\n",
        "      #to_append.append(df.iloc[i]['Time(s)'], new_x, new_y, new_z)\n",
        "      to_append.extend((time, new_x, new_y, new_z))\n",
        "      a_series = pd.Series(to_append, index = df.columns)\n",
        "      #print(a_series)\n",
        "      new_df = new_df.append(a_series, ignore_index=True)\n",
        "      #empty list\n",
        "      to_append=[]\n",
        "      i+=2\n",
        "\n",
        "  #convert to Gs\n",
        "  new_df.loc[:, 'ax(g)'] /= 9.81\n",
        "  new_df.loc[:, 'ay(g)'] /= 9.81\n",
        "  new_df.loc[:, 'az(g)'] /= 9.81\n",
        "  return new_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smHLZBhhEuIO"
      },
      "source": [
        "def get_jump(new_df):\n",
        "  import plotly.graph_objects as go\n",
        "  import pandas as pd\n",
        "  from scipy.signal import find_peaks\n",
        "  #basic code to identify peaks\n",
        "  #need more qualifications in case it identifies more jumps than expected (could combine with angular velocity for example)\n",
        "  #jump acc >2g for taekoff in general (B jump)\n",
        "  #find minima\n",
        "  y2 = new_df['ax(g)']\n",
        "  #find index of local minima based on conditions\n",
        "  indices = find_peaks(y2, height=2, distance=15)\n",
        "  return indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LW6G0lusFWsp"
      },
      "source": [
        "def find_takeoff(new_df, elem):\n",
        "  #find takeoff\n",
        "  pk_index = new_df.loc[new_df['ax(g)'] == elem].index[0] #retrieves first instance\n",
        "  dat = new_df.iloc[pk_index-6: pk_index+1,]\n",
        "  dat = dat.reset_index(drop=True)\n",
        "\n",
        "  #look at 4 points before peak to find take-off velocity\n",
        "  #loop to find points before and after 0.94\n",
        "  x = []\n",
        "  y = []\n",
        "  for i in range(len(dat)-1):\n",
        "    if dat.loc[i,\"ax(g)\"]<0.94 and dat.loc[i+1,\"ax(g)\"]>=0.94:\n",
        "      x.append(dat.loc[i,\"Time(s)\"])\n",
        "      x.append(dat.loc[i+1,\"Time(s)\"])\n",
        "      y.append(dat.loc[i,\"ax(g)\"])\n",
        "      y.append(dat.loc[i+1,\"ax(g)\"])\n",
        "      break\n",
        "    else:\n",
        "      pass\n",
        "\n",
        "  #interpolate acc at take-off\n",
        "  x_takeoff = np.interp(0.94, x, y)\n",
        "  return x_takeoff"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NHIYEIZFWsq"
      },
      "source": [
        "def find_landing(new_df, elem):\n",
        "  #find landing\n",
        "  pk_index = new_df.loc[new_df['ax(g)'] == elem].index[0] #retrieves first instance\n",
        "  dat = new_df.iloc[pk_index: pk_index+7,]\n",
        "  dat = dat.reset_index(drop=True)\n",
        "\n",
        "  #look at 4 points before peak to find take-off velocity\n",
        "  #loop to find points before and after 0.94\n",
        "  x = []\n",
        "  y = []\n",
        "  for i in range(len(dat)-1):\n",
        "    if dat.loc[i,\"ax(g)\"]>=0.94 and dat.loc[i+1,\"ax(g)\"]<0.94:\n",
        "      x.append(dat.loc[i,\"Time(s)\"])\n",
        "      x.append(dat.loc[i+1,\"Time(s)\"])\n",
        "      y.append(dat.loc[i,\"ax(g)\"])\n",
        "      y.append(dat.loc[i+1,\"ax(g)\"])\n",
        "      break\n",
        "    else:\n",
        "      pass\n",
        "\n",
        "  #interpolate acc at take-off\n",
        "  x_landing = np.interp(0.94, x, y)\n",
        "  return x_landing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPrjBGxoFWss"
      },
      "source": [
        "def jump_height(new_df, acc_ls):\n",
        "  #ls contains a list of peak acc identified when counting jumps\n",
        "  dist_ls=[]\n",
        "  for elem in acc_ls:\n",
        "    t_takeoff = find_takeoff(new_df, elem)\n",
        "    t_landing = find_landing(new_df, elem)\n",
        "    flight_time = t_landing-t_takeoff\n",
        "    jump_height = (0.982*flight_time)/8\n",
        "    \n",
        "    #store each estimation in dist_ls\n",
        "    dist_ls.append(jump_height)\n",
        "  return dist_ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jMIlLPqFxar"
      },
      "source": [
        "#normalize data\n",
        "def normalize(df):\n",
        "    result = df.copy()\n",
        "    for feature_name in df.columns: #normalize by rows\n",
        "      if feature_name != \"Time\": #only normalize accelerations\n",
        "        max_value = df[feature_name].max()\n",
        "        min_value = df[feature_name].min()\n",
        "        result[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)\n",
        "    return result\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "br3C5FFtF7dR"
      },
      "source": [
        "#function for differentiating jumps\n",
        "\n",
        "def ML_processing(new_df, all_acc_ls):\n",
        "  lst=[]\n",
        "  for elem in all_acc_ls:\n",
        "    pk_index = new_df.loc[new_df['ax(g)'] == elem].index[0] #retrieves first instance\n",
        "    shaped_data = new_df.iloc[pk_index-5: pk_index+20,]\n",
        "    #we need to only look at x_axis\n",
        "    df = shaped_data.iloc[:,3]\n",
        "    df = pd.DataFrame(df)\n",
        "\n",
        "    #transform dataframe into list to store multiple\n",
        "    inp_norm = np.array(normalize(df))\n",
        "    arr = inp_norm.reshape(1,25)\n",
        "    lst.append(arr)\n",
        "  \n",
        "  return lst"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4R5pYk4sF7dU"
      },
      "source": [
        "def diff_jumps(lst, filename):\n",
        "  lst_class=[]\n",
        "  x_test = np.vstack(lst)\n",
        "\n",
        "  # load the model from disk\n",
        "  loaded_model = pickle.load(open(filename, 'rb'))\n",
        "  #put into model for classification\n",
        "  #rfc_predict = loaded_model.predict(x)\n",
        "\n",
        "  for i in rfc_predict:\n",
        "    if i == 1:\n",
        "      lst_class.append('Approach jump')\n",
        "    else:\n",
        "      lst_class.append('Block jump')\n",
        "\n",
        "  #count different types of jumps\n",
        "  #from collections import Counter\n",
        "  #z = ['Block jump', 'Approach jump']\n",
        "  #dict_class = Counter(z)\n",
        "  #dict_class = {\"Block jump\":5, \"Approach jump\":1}\n",
        "  #lst_class = ['Block jump', 'Approach jump', 'Block jump', 'Block jump', 'Block jump', 'Block jump']\n",
        "  return dict_class,lst_class"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sh8AChnF7dW"
      },
      "source": [
        "def get_jump_stats(jump_dict, class_lst, height):\n",
        "  count_block = jump_dict.get(\"Block jump\")\n",
        "  count_approach = jump_dict.get(\"Approach jump\")\n",
        "\n",
        "  #split into block and approach jumps\n",
        "  b_lst=[]\n",
        "  a_lst=[]\n",
        "\n",
        "  for i in range(len(class_lst)):\n",
        "    if class_lst[i]==\"Block jump\":\n",
        "      b_lst.append(height[i])\n",
        "    else:\n",
        "      a_lst.append(height[i])\n",
        "\n",
        "  #find avg and max block jump height\n",
        "  if len(b_lst)==0:\n",
        "    avg_block_height=0\n",
        "    max_block_height=0\n",
        "  else:\n",
        "    avg_block_height = sum(b_lst)/len(b_lst)\n",
        "    max_block_height = max(b_lst)\n",
        "\n",
        "  #find avg and max approach jump height\n",
        "  if len(a_lst)==0:\n",
        "      avg_approach_height=0\n",
        "      max_approach_height=0\n",
        "  else:\n",
        "    avg_approach_height = sum(a_lst)/len(a_lst)\n",
        "    max_approach_height = max(a_lst)\n",
        "\n",
        "  return({\"Block\":[count_block, avg_block_height, max_block_height], \n",
        "          \"Approach\":[count_approach, avg_approach_height, max_approach_height]})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lf2u4Vsvp74C"
      },
      "source": [
        "##Final functions to get the required variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "7EbWzgPDxIE9",
        "outputId": "32a1c27a-235b-4f66-a854-131ce7205b70"
      },
      "source": [
        "link=\"session1.csv\"\n",
        "data_processing_NEW(link)\n",
        "new_df = data_processing_NEW(link)\n",
        "new_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time(s)</th>\n",
              "      <th>ax(g)</th>\n",
              "      <th>ay(g)</th>\n",
              "      <th>az(g)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000</td>\n",
              "      <td>3.190430</td>\n",
              "      <td>3.819491</td>\n",
              "      <td>3.337512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.306</td>\n",
              "      <td>3.178966</td>\n",
              "      <td>3.903642</td>\n",
              "      <td>3.358245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.583</td>\n",
              "      <td>3.235799</td>\n",
              "      <td>3.849005</td>\n",
              "      <td>3.230432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.883</td>\n",
              "      <td>3.790953</td>\n",
              "      <td>3.707533</td>\n",
              "      <td>3.807052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.179</td>\n",
              "      <td>2.645765</td>\n",
              "      <td>3.912668</td>\n",
              "      <td>2.302818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>45.936</td>\n",
              "      <td>3.221408</td>\n",
              "      <td>3.864859</td>\n",
              "      <td>3.279947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144</th>\n",
              "      <td>46.242</td>\n",
              "      <td>3.225798</td>\n",
              "      <td>3.834126</td>\n",
              "      <td>3.242628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>46.527</td>\n",
              "      <td>3.271654</td>\n",
              "      <td>3.811930</td>\n",
              "      <td>3.309217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>46.797</td>\n",
              "      <td>3.231896</td>\n",
              "      <td>3.824857</td>\n",
              "      <td>3.314339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>47.061</td>\n",
              "      <td>3.130671</td>\n",
              "      <td>3.751195</td>\n",
              "      <td>3.490448</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>148 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Time(s)     ax(g)     ay(g)     az(g)\n",
              "0      0.000  3.190430  3.819491  3.337512\n",
              "1      0.306  3.178966  3.903642  3.358245\n",
              "2      0.583  3.235799  3.849005  3.230432\n",
              "3      0.883  3.790953  3.707533  3.807052\n",
              "4      1.179  2.645765  3.912668  2.302818\n",
              "..       ...       ...       ...       ...\n",
              "143   45.936  3.221408  3.864859  3.279947\n",
              "144   46.242  3.225798  3.834126  3.242628\n",
              "145   46.527  3.271654  3.811930  3.309217\n",
              "146   46.797  3.231896  3.824857  3.314339\n",
              "147   47.061  3.130671  3.751195  3.490448\n",
              "\n",
              "[148 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lI7h76ep-JR",
        "outputId": "0025c3f0-a248-4a8c-bc50-24ad99779e7e"
      },
      "source": [
        "#calling of basic functions\n",
        "#new_df = data_processing(pd.read_excel('Book2.xlsx')) #should get from firebase\n",
        "link=\"session1.csv\"\n",
        "get_csv()\n",
        "data_processing_NEW(link)\n",
        "new_df = data_processing_NEW(link)\n",
        "jump_data = get_jump(new_df) \n",
        "\n",
        "#find jump height of all jumps\n",
        "total_jump = len(jump_data[0])#total jumps\n",
        "all_jump_acc = jump_data[1][\"peak_heights\"]#list of all recorded peak accelerations\n",
        "height = jump_height(new_df, all_jump_acc)\n",
        "\n",
        "#differentiate jumps\n",
        "jump_lst = ML_processing(new_df, all_jump_acc)\n",
        "filename = \"/content/drive/MyDrive/finalized_model.sav\"\n",
        "jump_dict, class_lst = diff_jumps(jump_lst, filename)\n",
        "final_dict = get_jump_stats(jump_dict, class_lst, height)\n",
        "final_dict\n",
        "\n",
        "#final_dict - dictionary of stats for different jumps\n",
        "#[counts, avg height, max height]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Approach': [1, 0.21748649999999997, 0.21748649999999997],\n",
              " 'Block': [5, 0.16062934999999998, 0.22335425]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 220
        }
      ]
    }
  ]
}